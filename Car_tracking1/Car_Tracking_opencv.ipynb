{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4322ae-07b3-4079-9db3-04c3a78fa15c",
   "metadata": {},
   "source": [
    "# Project: Car Detection and Tracking using OpenCV\r\n",
    "\r\n",
    "This project implements a simple vehicle detection and tracking system using Python and OpenCV.  \r\n",
    "It uses background subtraction and a distance-based tracking algorithm to identify and follow moving cars in a video feed.\r\n",
    "\r\n",
    "-- \n",
    "## ðŸ” Steps Breakdown\r\n",
    "\r\n",
    "### 1. **Video Input & ROI Selection**\r\n",
    "Capture frames from a traffic video using OpenCV and define a **Region of Interest (ROI)** â€” the part of the frame where vehicles are expected.  \r\n",
    "This reduces noise and focuses processing power on the relevant area.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 2. **Background Subtraction**\r\n",
    "Apply `cv2.createBackgroundSubtractorMOG2()` to distinguish moving objects from the static background.  \r\n",
    "This isolates cars and other vehicles from the road when the camera is stable.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 3. **Thresholding**\r\n",
    "Convert the background mask into a binary image using `cv2.threshold()` â€”  \r\n",
    "white pixels represent detected motion, and black pixels represent static background.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 4. **Mask Cleaning (Morphological Operations)**\r\n",
    "Apply operations like **erosion and dilation** (e.g., `cv2.morphologyEx`) to:\r\n",
    "- Remove small noisy areas\r\n",
    "- Fill holes in detected motion blobs\r\n",
    "- Improve contour detection\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 5. **Finding Contours**\r\n",
    "Detect **contours** (object outlines) in the thresholded mask using `cv2.findContours()`.  \r\n",
    "Each contour corresponds to a potential vehicle.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 6. **Filtering Small Contours**\r\n",
    "Ignore small contours that are unlikely to be vehicles based on their **area size**.  \r\n",
    "This reduces false positives caused by shadows, small debris, or distant objects.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 7. **Bounding Boxes & Detection List**\r\n",
    "For each valid contour:\r\n",
    "- Calculate its bounding rectangle using `cv2.boundingRect()`\r\n",
    "- Add it to a **detections list** for tracking\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 8. **Object Tracking with Euclidean Distance**\r\n",
    "Use a custom `EuclideanDistTracker` class to:\r\n",
    "- Assign a unique **ID** to each detected vehicle\r\n",
    "- Match vehicles across frames based on proximity\r\n",
    "- Maintain consistent IDs as cars move\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 9. **Drawing Rectangles with IDs**\r\n",
    "For each tracked vehicle:\r\n",
    "- Draw a **rectangle** around it\r\n",
    "- Display the **ID** using `cv2.putText()` for visual feedback\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 10. **Saving Output Video (Optional)**\r\n",
    "Write each processed frame to a new video file using `cv2.VideoWriter()`  \r\n",
    "This creates an output with sual tracking results for further analysis or presentation.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## âœ… Outcome\r\n",
    "\r\n",
    "- Tracks moving cars in a video stream\r\n",
    "- Assigns consistent IDs to each vehicle\r\n",
    "- Visualizes bounding boxes motion in real time\r\n",
    "- Optionally exports results as a video file\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## ðŸ› ï¸ Possible Extensions\r\n",
    "\r\n",
    "- Vehicle counting (entry/exit zones)\r\n",
    "- Speed estimation\r\n",
    "- License plate detection\r\n",
    "- Deep learning-based object detection (e.g., YOLO, SSD)\r\n",
    "- GUI dashboard for live monitoring and analytics\r\n",
    "\r\n",
    "---\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a83edbd-8d49-4fb4-895b-a1513aed25ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\morph.dispatch.cpp:1163: error: (-215:Assertion failed) !_src.empty() in function 'cv::morphologyEx'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Optional: Clean mask\u001b[39;00m\n\u001b[0;32m     45\u001b[0m kernel \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetStructuringElement(cv2\u001b[38;5;241m.\u001b[39mMORPH_ELLIPSE, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 46\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmorphologyEx(mask, cv2\u001b[38;5;241m.\u001b[39mMORPH_OPEN, kernel)\n\u001b[0;32m     49\u001b[0m contours, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(mask, cv2\u001b[38;5;241m.\u001b[39mRETR_TREE, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m     50\u001b[0m detections \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\morph.dispatch.cpp:1163: error: (-215:Assertion failed) !_src.empty() in function 'cv::morphologyEx'\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from tracker import EuclideanDistTracker\n",
    "\n",
    "# Set working directory if needed\n",
    "# os.chdir(\"D:/object tracking/object_tracking\")\n",
    "\n",
    "# Create tracker object\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture(\"highway.mp4\")\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error loading video.\")\n",
    "    exit()\n",
    "\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "# Save output video with proper dimensions\n",
    "result = cv2.VideoWriter('output_tracking.mp4', \n",
    "                         cv2.VideoWriter_fourcc(*'XVID'),\n",
    "                         20, (frame_width, frame_height))\n",
    "\n",
    "# Background subtractor\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Region of Interest (ROI) - adjust as needed\n",
    "    roi = frame[340: 720, 500: 800]\n",
    "\n",
    "    # 1. Object Detection\n",
    "    mask = object_detector.apply(roi)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Optional: Clean mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 100:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            detections.append([x, y, w, h])\n",
    "\n",
    "    # 2. Object Tracking\n",
    "    boxes_ids = tracker.update(detections)\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, id = box_id\n",
    "        cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(roi, f'ID {id}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "    # Show frames\n",
    "    frame[340: 720, 500: 800] = roi  # Update the main frame with ROI overlay\n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    result.write(frame)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "result.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967121f5-c864-459a-bb55-4d3ba117d19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756631a-eec9-47a0-86ec-a93d6bc3e18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
